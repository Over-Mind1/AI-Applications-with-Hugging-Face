{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e45c8",
   "metadata": {
    "id": "b45e45c8"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2159974",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2159974",
    "outputId": "aadb7002-b44b-455f-db24-2367cdf5a1b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "Qwen3_bot= pipeline(task=\"text-generation\",\n",
    "                       model=\"Qwen/Qwen3-0.6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727ee52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4727ee52",
    "outputId": "c2eb71c9-f959-44dc-f928-daaa13c76e7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12555, 374, 16391], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message=\"what is transformer\"\n",
    "Qwen3_bot.tokenizer(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71aded",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da71aded",
    "outputId": "c6dfab04-d90b-4093-ca98-aa9b814ae1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('User', 'what is transformer'), ('Bot', 'what is transformer in machine learning\\n\\nTransformer is a type of neural network architecture used in machine learning, particularly in natural language processing (NLP). It is designed to handle sequential data, such as text, by using self-attention mechanisms. The key components of the Transformer model include the encoder and the decoder, each of which processes the input data in a way that allows the model to capture long-range dependencies between words.\\n\\nThe Transformer architecture is different from the RNNs and LSTMs used in previous models because it uses self-attention, which allows the model to focus on the most relevant parts of the input at any given time. This makes the Transformer more efficient and capable of handling longer sequences of text compared to RNNs and LSTMs.\\n\\nIn')]\n"
     ]
    }
   ],
   "source": [
    "conversation = []\n",
    "bot_response = Qwen3_bot(\n",
    "    user_message,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    max_new_tokens=150,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "conversation.append((\"User\", user_message))\n",
    "conversation.append((\"Bot\", bot_response[0]['generated_text']))\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uIPsxF48NcN6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "uIPsxF48NcN6",
    "outputId": "5d826899-0427-411f-95d0-861915ec3ea5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'what is transformer in machine learning\\n\\nTransformer is a type of neural network architecture used in machine learning, particularly in natural language processing (NLP). It is designed to handle sequential data, such as text, by using self-attention mechanisms. The key components of the Transformer model include the encoder and the decoder, each of which processes the input data in a way that allows the model to capture long-range dependencies between words.\\n\\nThe Transformer architecture is different from the RNNs and LSTMs used in previous models because it uses self-attention, which allows the model to focus on the most relevant parts of the input at any given time. This makes the Transformer more efficient and capable of handling longer sequences of text compared to RNNs and LSTMs.\\n\\nIn'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RDd4WbY-DnT9",
   "metadata": {
    "id": "RDd4WbY-DnT9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
